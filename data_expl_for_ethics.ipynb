{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import f_oneway\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from gensim.models import Word2Vec\n",
    "# from nltk.tokenize import word_tokenize  # You may need to install nltk and download punkt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# import matplotlib.pyplot as plt\n",
    "from utilities import *\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# from transformers import BertTokenizer, BertForSequenceClassification, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick full or smaller version of dataset\n",
    "df = pd.read_csv('data/modelready_220423.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot columns = 772, numeric type columns = 765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_number</th>\n",
       "      <th>company_name</th>\n",
       "      <th>countries_in_family</th>\n",
       "      <th>publn_nr</th>\n",
       "      <th>primary_cpc</th>\n",
       "      <th>abstract</th>\n",
       "      <th>description_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US-8623043-B1</td>\n",
       "      <td>Entellus Medical, Inc.</td>\n",
       "      <td>['AU' 'EP' 'CA' 'US']</td>\n",
       "      <td>8623043</td>\n",
       "      <td>A61M29/02</td>\n",
       "      <td>A method of treating a constricted sinus passa...</td>\n",
       "      <td>RELATED APPLICATIONS \\n     This Application i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publication_number            company_name    countries_in_family publn_nr  \\\n",
       "0      US-8623043-B1  Entellus Medical, Inc.  ['AU' 'EP' 'CA' 'US']  8623043   \n",
       "\n",
       "  primary_cpc                                           abstract  \\\n",
       "0   A61M29/02  A method of treating a constricted sinus passa...   \n",
       "\n",
       "                                    description_text  \n",
       "0  RELATED APPLICATIONS \\n     This Application i...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print non-numerical columns\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "print(f'tot columns = {len(df.columns)}, numeric type columns = {len(df.select_dtypes(include=numerics).columns)}' ) # not too many non-numeric columns\n",
    "df.select_dtypes(include = ['object']).head(1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract unique countries in the df\n",
    "unique_values = set()\n",
    "df['countries_in_family'].apply(lambda x: unique_values.update(x.strip(\"[]\").replace(\"'\", \"\").split())) \n",
    "\n",
    "# Create new columns for each unique value\n",
    "for value in unique_values:\n",
    "    # each country has a column (1 if the patent belong to the country 0 otherwise)\n",
    "    df[value] = df['countries_in_family'].apply(lambda x: 1 if value in x else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing value in description text 0\n"
     ]
    }
   ],
   "source": [
    "df = df[df.abstract.notna()].copy() # drop all samples without abstract\n",
    "print('missing value in description text' , df.description_text.isna().sum()) # description_text doesn't have mssing vales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode company names\n",
    "df['company_name_encoded'] = df.company_name.astype('category').cat.codes  # encode companies\n",
    "\n",
    "# remove non-numeric columns\n",
    "df_columns_dropped = df.drop(['publication_number', 'company_name', 'countries_in_family', 'publn_nr','primary_cpc'], axis = 1)\n",
    "\n",
    "# f0_ has the same value as commercialization, the other two shouldn't be used\n",
    "df_columns_dropped = df_columns_dropped.drop(['f0_', 'centrality', 'similarity'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove text as I can't compute min and max on it\n",
    "text = df_columns_dropped[['abstract', 'description_text']] # putting them aside for later\n",
    "df_columns_dropped.drop(['abstract', 'description_text'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting what we'll try to predict\n",
    "y = df_columns_dropped['commercialized']\n",
    "df_columns_dropped.drop('commercialized', axis= 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns where all the value are the same (only one unique value) they would be zero if I apply min max rescaling\n",
    "nunique = df_columns_dropped.nunique()\n",
    "cols_to_drop = nunique[nunique == 1].index\n",
    "df_clean = df_columns_dropped.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting train and test and trying best preprocessing on training set\n",
    "# all preprocessing will be done on X_train and only in the end tested on X_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_clean, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select best way to fill missin values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method:mean\n",
      "Average F1 Score: 0.8763201883062935\n",
      "Average Accuracy: 0.892427433252333\n",
      "Average Precision: 0.8875829759923939\n",
      "Average Recall: 0.8653785071466384\n",
      "\n",
      "method:median\n",
      "Average F1 Score: 0.8764296230570316\n",
      "Average Accuracy: 0.8925439888011878\n",
      "Average Precision: 0.8878625594971841\n",
      "Average Recall: 0.8653255690841716\n",
      "\n",
      "method:most_frequent\n",
      "Average F1 Score: 0.8767494768495926\n",
      "Average Accuracy: 0.8928703780379091\n",
      "Average Precision: 0.8885779562606804\n",
      "Average Recall: 0.8652726310217046\n",
      "\n",
      "method:zero\n",
      "Average F1 Score: 0.8767252986105802\n",
      "Average Accuracy: 0.8928470571442881\n",
      "Average Precision: 0.8885315452810889\n",
      "Average Recall: 0.8652726310217046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: rerun\n",
    "# find best method for filling missing values\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "#rescale \n",
    "scaler = ('scaler', StandardScaler())\n",
    "filling_methods = ['mean', 'median', 'most_frequent', 'zero']\n",
    "\n",
    "for method in filling_methods:\n",
    "    # Make a copy of the original data to avoid modifying it\n",
    "    data_filled = X_train.copy()\n",
    "\n",
    "    # Fill NaN values based on the selected method\n",
    "    if method == 'zero':\n",
    "        # data_filled = data_filled.fillna(0)  # You can choose any constant value\n",
    "        imputer =  ('imputer', SimpleImputer(strategy='constant', fill_value=0))\n",
    "    else:\n",
    "        imputer = ('imputer', SimpleImputer(strategy=method, keep_empty_features=False))\n",
    "    \n",
    "    # default max_iter was reached, so increased it\n",
    "    model = ('model', LogisticRegression(max_iter=1000))\n",
    "\n",
    "    #rescale \n",
    "    # scaler.fit(data_filled)\n",
    "    # data_filled = scaler.transform(data_filled)\n",
    "\n",
    "    pipeline = Pipeline([imputer ,scaler, model])\n",
    "\n",
    "    # Perform cross-validation and print the mean score\n",
    "    scores_dict = cross_validate(estimator=pipeline, X=data_filled, y=y_train, n_jobs=5, cv=5,scoring=['f1', 'accuracy', 'precision', 'recall'])\n",
    "\n",
    "    accuracies.append(scores_dict[\"test_accuracy\"])\n",
    "\n",
    "    # Print the results\n",
    "    print(f'method:{method}')\n",
    "    print(f'Average F1 Score: {np.mean(scores_dict[\"test_f1\"])}')\n",
    "    print(f'Average Accuracy: {np.mean(scores_dict[\"test_accuracy\"])}')\n",
    "    print(f'Average Precision: {np.mean(scores_dict[\"test_precision\"])}')\n",
    "    print(f'Average Recall: {np.mean(scores_dict[\"test_recall\"])}')\n",
    "    print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests to explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_number</th>\n",
       "      <th>company_name</th>\n",
       "      <th>commercialized</th>\n",
       "      <th>vpm_patent_score</th>\n",
       "      <th>backward_citations_app</th>\n",
       "      <th>backward_citations_exa</th>\n",
       "      <th>forward_citations</th>\n",
       "      <th>total_nb_claims</th>\n",
       "      <th>nb_indep_claims</th>\n",
       "      <th>family_size</th>\n",
       "      <th>...</th>\n",
       "      <th>GR</th>\n",
       "      <th>RO</th>\n",
       "      <th>GE</th>\n",
       "      <th>CR</th>\n",
       "      <th>HK</th>\n",
       "      <th>IN</th>\n",
       "      <th>DE</th>\n",
       "      <th>HN</th>\n",
       "      <th>KR</th>\n",
       "      <th>company_name_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US-8623043-B1</td>\n",
       "      <td>Entellus Medical, Inc.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>140</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US-9192748-B2</td>\n",
       "      <td>Entellus Medical, Inc.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US-8888686-B2</td>\n",
       "      <td>Entellus Medical, Inc.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US-8986340-B2</td>\n",
       "      <td>Entellus Medical, Inc.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>162</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US-9320876-B2</td>\n",
       "      <td>Entellus Medical, Inc.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>208</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63342</th>\n",
       "      <td>US-7357652-B1</td>\n",
       "      <td>Leviton</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>75</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63343</th>\n",
       "      <td>US-8958680-B2</td>\n",
       "      <td>Leviton</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63346</th>\n",
       "      <td>US-9515437-B2</td>\n",
       "      <td>Leviton</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>64</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63347</th>\n",
       "      <td>US-9551454-B2</td>\n",
       "      <td>Leviton</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63348</th>\n",
       "      <td>US-9596727-B2</td>\n",
       "      <td>Leviton</td>\n",
       "      <td>0</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53616 rows × 857 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      publication_number            company_name  commercialized  \\\n",
       "0          US-8623043-B1  Entellus Medical, Inc.               0   \n",
       "1          US-9192748-B2  Entellus Medical, Inc.               0   \n",
       "2          US-8888686-B2  Entellus Medical, Inc.               0   \n",
       "3          US-8986340-B2  Entellus Medical, Inc.               0   \n",
       "4          US-9320876-B2  Entellus Medical, Inc.               0   \n",
       "...                  ...                     ...             ...   \n",
       "63342      US-7357652-B1                 Leviton               1   \n",
       "63343      US-8958680-B2                 Leviton               1   \n",
       "63346      US-9515437-B2                 Leviton               1   \n",
       "63347      US-9551454-B2                 Leviton               1   \n",
       "63348      US-9596727-B2                 Leviton               0   \n",
       "\n",
       "       vpm_patent_score  backward_citations_app  backward_citations_exa  \\\n",
       "0              0.000000                     140                      18   \n",
       "1              0.000000                     203                      33   \n",
       "2              0.000000                      69                       8   \n",
       "3              0.000000                     162                       2   \n",
       "4              0.000000                     208                       2   \n",
       "...                 ...                     ...                     ...   \n",
       "63342          0.986301                      75                      12   \n",
       "63343          0.986301                      15                       8   \n",
       "63346          0.986301                      64                      17   \n",
       "63347          0.986301                       1                      64   \n",
       "63348          0.986301                      50                       2   \n",
       "\n",
       "       forward_citations  total_nb_claims  nb_indep_claims  family_size  ...  \\\n",
       "0                     22               11                1           18  ...   \n",
       "1                      2               16                2            5  ...   \n",
       "2                      2               15                1            2  ...   \n",
       "3                      3               22                1           23  ...   \n",
       "4                      0               10                2           18  ...   \n",
       "...                  ...              ...              ...          ...  ...   \n",
       "63342                 11               29                3            5  ...   \n",
       "63343                  2               19                1            7  ...   \n",
       "63346                  0               19                3            1  ...   \n",
       "63347                  0               37                5            2  ...   \n",
       "63348                  1               26                3            4  ...   \n",
       "\n",
       "       GR RO  GE  CR  HK  IN  DE  HN  KR  company_name_encoded  \n",
       "0       0  0   0   0   0   0   0   0   0                   196  \n",
       "1       0  0   0   0   0   0   0   0   0                   196  \n",
       "2       0  0   0   0   0   0   0   0   0                   196  \n",
       "3       0  0   0   0   0   0   0   0   0                   196  \n",
       "4       0  0   0   0   0   0   0   0   0                   196  \n",
       "...    .. ..  ..  ..  ..  ..  ..  ..  ..                   ...  \n",
       "63342   0  0   0   0   0   0   0   0   0                   326  \n",
       "63343   0  0   0   0   0   0   0   0   0                   326  \n",
       "63346   0  0   0   0   0   0   0   0   0                   326  \n",
       "63347   0  0   0   0   0   0   0   0   0                   326  \n",
       "63348   0  0   0   0   0   0   0   0   0                   326  \n",
       "\n",
       "[53616 rows x 857 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                            ['AU' 'EP' 'CA' 'US']\n",
       "1                                           ['US']\n",
       "2                                           ['US']\n",
       "3        ['JP' 'US' 'ES' 'HU' 'CN' 'EP' 'PL' 'DK']\n",
       "4                            ['EP' 'CA' 'AU' 'US']\n",
       "                           ...                    \n",
       "63342                        ['US' 'CA' 'MX' 'CN']\n",
       "63343                                  ['CA' 'US']\n",
       "63346                                       ['US']\n",
       "63347                                  ['US' 'CA']\n",
       "63348                                  ['GB' 'US']\n",
       "Name: countries_in_family, Length: 53616, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['countries_in_family']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53616\n",
      "53616\n",
      "The percentage of 'US' in the 'countries_in_family' column is: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of 'US'\n",
    "\n",
    "total_rows = df.shape[0]\n",
    "print(total_rows)\n",
    "\n",
    "us_occurrences = df['countries_in_family'].str.count('US').sum()\n",
    "print(us_occurrences)\n",
    "\n",
    "# Calculate percentage\n",
    "us_percentage = (us_occurrences / total_rows) * 100\n",
    "\n",
    "print(f\"The percentage of 'US' in the 'countries_in_family' column is: {us_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of 'Abbott' in the 'company_name' column is: 7.77%\n"
     ]
    }
   ],
   "source": [
    "# Find the most frequent company in the dataset\n",
    "\n",
    "total_rows = df.shape[0] \n",
    "most_frequent_company = df['company_name'].mode().iloc[0]\n",
    "most_frequent_occurrences = df['company_name'].value_counts().max()  # Count occurrences of the most frequent company\n",
    "\n",
    "# Calculate percentage\n",
    "most_frequent_percentage = (most_frequent_occurrences / total_rows) * 100\n",
    "\n",
    "print(f\"The percentage of '{most_frequent_company}' in the 'company_name' column is: {most_frequent_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
